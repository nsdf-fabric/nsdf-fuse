#!/bin/bash

# when any command fails
set -e 

# DANGEROUS (!) verbose
# uncomment only if needed
if [[ "$DEBUG" == "1" ]] ; then
	set -x
fi

KiB=$(( 1024 ))
MiB=$(( $KiB * 1024 ))
GiB=$(( $MiB * 1024 ))


# /////////////////////////////////////////////////////////////////
function DropCache() {
	# see https://www.tecmint.com/clear-ram-memory-cache-buffer-and-swap-space-on-linux/
	sync
	sudo sh -c "/usr/bin/echo 3 > /proc/sys/vm/drop_caches"
}

# /////////////////////////////////////////////////////////////////
function Retry() {
	local count=0
	until "$@"; do
		count=$(($count + 1))
		if [ $count -lt 20 ]; then
			echo "... retry attempt failed, retrying"
			sleep 5
		else
			echo "Retry $@ failed , giving up."
			exit 1
		fi
	done
	echo "Retry succeded"
	return 0
}

# /////////////////////////////////////////////////////////////////
function CheckMount() {
	__result__=$(mount | grep ${TEST_DIR})
	if [ -z "$__result__" ] ; then
		mount
		echo "ERROR: ${TARGET} cannot mount ${TEST_DIR} "
		exit 1
	fi
}

# /////////////////////////////////////////////////////////////////
function CleanAll() {

	echo "Cleaning all..."

	BUCKETS_DIR=${BUCKETS_DIR:?}

	for I in {1..3}
	do
		
		# unmount filesystem
		__mounted__=$(mount | grep ${BUCKETS_DIR} | cut -d" " -f3)
		for it in $__mounted__; do 
			echo "Unmounting $it"
			sudo umount -l $it
			sudo umount -f $it
		done

		# remove buckets
		__buckets__=$(aws s3 ls | grep "nsdf-fuse-test" | cut -d" " -f3)
		for it in $__buckets__; do 
			echo "Removing bucket $it"
			echo "aws s3 rb s3://$it --force "
			aws s3 rb s3://$it --force 
		done

		# remove bucket dir
		
		sudo rm -Rf ${BUCKETS_DIR}/*

	done

	echo "Mount"
	$(mount | grep ${BUCKETS_DIR} | cut -d" " -f3)

	echo "Buckets"
	$(aws s3 ls | grep "nsdf-fuse-test" | cut -d" " -f3)

	echo "${BUCKETS_DIR}"
	find ${BUCKETS_DIR}/
}


# /////////////////////////////////////////////////////////////////////
function BeginTest() {
	echo "Begin test [$1]"
	SECONDS=0
	pids=""
	FuseUp
}

# /////////////////////////////////////////////////////////////////////
function EndTest() {
	echo "Waiting for PIDS=$pids"
    for p in $pids; do
        if wait $p; then
            : # echo "process $p success"
        else
            echo "process $p Failure!"
            exit 1
        fi
   done
	sync 
	FuseDown
	echo "end test [$1] $(( ( $TOT_GB * $GiB ) / ( $MiB * ${SECONDS} ) ))MiB/sec TOT_SECONDS=$SECONDS "
	
}

# /////////////////////////////////////////////////////////////////////
function RunFioBenchmark() {

	TOT_GB=4

	# inspired by https://juicefs.com/docs/cloud/single_node_benchmark/
	BeginTest fio-seq-1-write
	fio  --name=fio-seq-1-write  --group_reporting=1 --directory=${TEST_DIR} --rw=write --bs=256k --size=${TOT_GB}G --refill_buffers 
	EndTest fio-seq-1-write
	nsdf-fuse ${TARGET} clean-bucket

	BeginTest fio-seq-1-read
	fio  --name=fio-seq-1-read --group_reporting=1 --directory=${TEST_DIR} --rw=read --bs=256k --size=${TOT_GB}G --refill_buffers 
	EndTest fio-seq-1-read
	nsdf-fuse ${TARGET} clean-bucket

	BeginTest fio-seq-n-write	
	fio  --name=fio-seq-n-write --group_reporting=1 --directory=${TEST_DIR} --rw=write --bs=256k  --size=${TOT_GB}G --refill_buffers  --numjobs=16  
	EndTest fio-seq-n-write	
	nsdf-fuse ${TARGET} clean-bucket

	BeginTest fio-seq-n-read
	fio  --name=fio-seq-n-read --group_reporting=1 --directory=${TEST_DIR} --rw=read --bs=256k  --size=${TOT_GB}G --refill_buffers --numjobs=16 
	EndTest fio-seq-n-read
	nsdf-fuse ${TARGET} clean-bucket

	BeginTest fio-rand-1-write
	fio  --name=fio-rand-1-write --group_reporting=1 --directory=${TEST_DIR} --rw=randwrite --bs=256k --size=${TOT_GB}G --refill_buffers 
	EndTest fio-rand-1-write
	nsdf-fuse ${TARGET} clean-bucket

	BeginTest fio-rand-1-read
	fio  --name=fio-rand-1-read --group_reporting=1 --directory=${TEST_DIR} --rw=randread --bs=256k  --size=${TOT_GB}G 
	EndTest fio-rand-1-read
	nsdf-fuse ${TARGET} clean-bucket
}


# ///////////////////////////////////////////////////////////////////////
function RunSimpleBenchmark() {

	REMOTE=${TEST_DIR:?}
	LOCAL=/tmp/simple-benchmark

	# ////////////////////////////////////////// 
	# sequential

	# note: internally creating only one file of 1GB
	if [[ "1" == "1" ]] ; then
		TOT_GB=8

		# generate 1Gib File
		mkdir -p $LOCAL
		rm -Rf $LOCAL/*
		head -c $GiB /dev/urandom > $LOCAL/1GB

		# simple-seq-1
		BeginTest simple-seq-1-write
		for (( I=0 ; I < TOT_GB ; I++ )) ; do 
		  cp $LOCAL/1GB $REMOTE/$I 
		done
		EndTest simple-seq-1-write

		BeginTest simple-seq-1-read
		for (( I=0 ;  I < TOT_GB ; I++ )) ; do 
		  cp $REMOTE/$I /dev/null 
		done
		EndTest simple-seq-1-read

		nsdf-fuse ${TARGET} clean-bucket

		# simple-seq-n
		BeginTest simple-seq-n-write
		for (( I=0 ; I < TOT_GB ; I++ )) ; do 
			cp $LOCAL/1GB $REMOTE/$I & 
			pids+=" $!"
		done
		EndTest simple-seq-n-write

		BeginTest simple-seq-n-read
		for (( I=0 ; I < TOT_GB ; I++ )) ; do 
			cp $REMOTE/$I /dev/null & 
			pids+=" $!"
		done
		EndTest simple-seq-n-read

		nsdf-fuse ${TARGET} clean-bucket
	fi

	# ///////////////////////////////////////////////
	# random

	if [[ "1" == "1" ]] ; then

		# 16 jobs in parallel, each job handling 2048 files of 64KB each, TOT=16*2048*65536=2GB
		# note: internally creating 2048*64Kb==128MiB
		NUM_JOBS=16
		NUM_FILES=2048
		FILESIZE=65536
		TOT_GB=$(( ( $NUM_JOBS * $NUM_FILES * $FILESIZE ) / ($GiB) ))  

		mkdir -p $LOCAL
		rm -Rf $LOCAL/*

		# generate random files
		for (( I=0 ; I < NUM_FILES ; I++ )) ; do 
			head -c $FILESIZE /dev/urandom > $LOCAL/$I 
		done

		# create directories
		FuseUp
		for (( I=0 ; I < NUM_JOBS ; I++ )) ; do 
			mkdir -p $REMOTE/$I
		done
		FuseDown

		# simple-rand-n
		BeginTest simple-rand-n-write
		for (( I=0 ; I < NUM_JOBS ; I++ )) ; do 
			find $LOCAL -type f -exec cp "{}" $REMOTE/$I/ \; & 
			pids+=" $!"
		done
		EndTest simple-rand-n-write

		BeginTest simple-rand-n-read
		for (( I=0 ; I < NUM_JOBS ; I++ )) ; do 
			find $REMOTE/$I -type f -exec cp "{}" /dev/null \; & 
			pids+=" $!"
		done
		EndTest simple-rand-n-read

		nsdf-fuse ${TARGET} clean-bucket
	fi
}

# //////////////////////////////////////////////////////////////////////////
function UpdateOS() {
	sudo apt -qq update
	sudo apt -qq install -y nload expect python3 python3-pip awscli fuse libfuse-dev net-tools
}

# //////////////////////////////////////////////////////////////////////////
function InstallFIO() {
	git clone https://github.com/axboe/fio
	pushd fio
	./configure
	make 
	sudo make install
	sudo cp /usr/local/bin/fio /usr/bin/fio 
	popd
	rm -Rf fio

	# check the version
	fio --version
}

# //////////////////////////////////////////////////////////////////
function Main() {

	# all test are meant to be temporary
	export BUCKETS_DIR=/tmp/buckets
	mkdir -p $BUCKETS_DIR

	if [[ "$1" == "clean-all" ]] ; then
		CleanAll
		exit 0

	elif [[ "$1" == "update-os" ]] ; then
		UpdateOS
		exit 0

	elif [[ "$1" == "install-fio" ]] ; then
		InstallFIO
		exit 0
	fi

	# target specific
	TARGET=${1:?}
	shift

	export BUCKET_NAME=nsdf-fuse-test-${TARGET}
	export BASE_DIR=${BUCKETS_DIR}/${BUCKET_NAME}
	export TEST_DIR=${BASE_DIR}/test
	export CACHE_DIR=${BASE_DIR}/cache
	export LOG_DIR=${BASE_DIR}/log

	echo "# BUCKET_NAME=${BUCKET_NAME} AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION} BASE_DIR=${BASE_DIR} TEST_DIR=${TEST_DIR} CACHE_DIR=${CACHE_DIR} LOG_DIR=${LOG_DIR}"

		 # make sure I have all the directories
	mkdir  -p ${BASE_DIR}  || true
	mkdir  -p ${TEST_DIR}  || true
	mkdir  -p ${CACHE_DIR} || true
	mkdir  -p ${LOG_DIR}   || true


	# add some functions (as CreateBucket, RemoveBucket, FuseUp and FuseDown)
	if   [[  "${TARGET}" == "geesefs" ]] ; then 
		source scripts/geesefs.sh 

	elif [[  "${TARGET}" == "goofys"  ]] ; then 
		source scripts/goofys.sh 

	elif [[  "${TARGET}" == "juicefs" ]] ; then 
		source scripts/juicefs.sh 

	elif [[  "${TARGET}" == "objectivefs" ]] ; then 
		source scripts/objectivefs.sh

	elif [[  "${TARGET}" == "rclone" ]] ; then 
		source scripts/rclone.sh	 

	elif [[  "${TARGET}" == "s3backer" ]] ; then 
		source scripts/s3backer.sh

	elif [[  "${TARGET}" == "s3fs" ]] ; then 
		source scripts/s3fs.sh
		  
	elif [[  "${TARGET}" == "s3ql" ]] ; then 
		source scripts/s3ql.sh
		  
	else
		echo "ERROR: unknown TARGET=${TARGET}"
	fi

	# //////////////////////////////////////////////////////////////
	while (( "$#" )) ; do

		set -e

		ACTION=${1:?}
		shift

		echo "Begin ACTION=${ACTION}" 

		if [[ "${ACTION}" == "install" ]] ; then
			Install_${TARGET}

		elif [[ "${ACTION}" == "uninstall" ]] ; then
			Uninstall_${TARGET}

		elif [[ "${ACTION}" == "create-bucket" ]] ; then
			CreateBucket 
			aws s3 ls | grep ${BUCKET_NAME}

		elif [[ "${ACTION}" == "remove-bucket" ]] ; then
			RemoveBucket 
			aws s3 ls

		elif [[ "${ACTION}" == "clean-bucket" ]] ; then
			SECONDS=0
			FuseUp 
			rm -Rf ${TEST_DIR}/* 
			FuseDown
			echo "${ACTION} done. Seconds: ${SECONDS}"

		elif [[ "${ACTION}" == "up" ]] ; then
			FuseUp 

		elif [[ "${ACTION}" == "down" ]] ; then
			FuseDown 

		elif [[ "${ACTION}" == "find" ]] ; then
			FuseUp 
			find ${TEST_DIR} 
			FuseDown 

		elif [[ "${ACTION}" == "touch" ]] ; then
			echo "it is working" > $TEST_DIR/it_is_working

		# "WARNING: remember to create-bucket
		elif [[ "${ACTION}" == "fio-benchmark" ]] ; then
			RunFioBenchmark
			exit 0

		elif [[ "${ACTION}" == "simple-benchmark" ]] ; then
			RunSimpleBenchmark
			exit 0

		else
			echo "ERROR: unknown ACTION=${ACTION}"
			exit 1
		fi

		echo "End ACTION=${ACTION}"
		echo ""

	done
}

if [[ $# -ge 1 ]]; then
	Main $@
fi




